{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 6 Tasks - Data Wrangling in Python\n",
        "\n",
        "This notebook demonstrates essential data wrangling skills using Python and pandas. We will work through data loading, cleaning, transformation, and aggregation tasks.\n",
        "\n",
        "**Author:** Your Name  \n",
        "**Date:** [Current Date]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1: Data Loading and Initial Exploration\n",
        "\n",
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your chosen dataset\n",
        "# Replace with your dataset path\n",
        "# data = pd.read_csv('path/to/your/dataset.csv')\n",
        "\n",
        "# For demonstration, we'll create a sample dataset with common data quality issues\n",
        "np.random.seed(123)\n",
        "\n",
        "sample_data = pd.DataFrame({\n",
        "    'id': range(1, 1001),\n",
        "    'name': [f'Customer {i}' for i in range(1, 1001)],\n",
        "    'age': np.random.choice([*range(18, 81), np.nan], 1000, p=[0.98/63] * 63 + [0.02]),\n",
        "    'income': np.round(np.random.normal(50000, 15000, 1000)),\n",
        "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', np.nan], 1000),\n",
        "    'purchase_date': pd.date_range('2020-01-01', '2023-12-31', periods=1000),\n",
        "    'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home', 'Sports'], 1000),\n",
        "    'amount': np.round(np.random.uniform(10, 500, 1000), 2)\n",
        "})\n",
        "\n",
        "# Introduce some data quality issues\n",
        "sample_data.loc[np.random.choice(1000, 50, replace=False), 'age'] = np.nan\n",
        "sample_data.loc[np.random.choice(1000, 30, replace=False), 'income'] = np.nan\n",
        "sample_data.loc[np.random.choice(1000, 25, replace=False), 'city'] = np.nan\n",
        "sample_data.loc[np.random.choice(1000, 10, replace=False), 'name'] = ''  # Empty strings\n",
        "sample_data.loc[np.random.choice(1000, 5, replace=False), 'name'] = '   '  # Whitespace only\n",
        "\n",
        "print(f\"Dataset shape: {sample_data.shape[0]} rows, {sample_data.shape[1]} columns\")\n",
        "print(f\"Column names: {', '.join(sample_data.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display First and Last Rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First 10 rows\n",
        "print(\"First 10 rows:\")\n",
        "sample_data.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Last 5 rows\n",
        "print(\"Last 5 rows:\")\n",
        "sample_data.tail(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2: Data Cleaning and Preprocessing\n",
        "\n",
        "## Handle Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for cleaning\n",
        "data_cleaned = sample_data.copy()\n",
        "\n",
        "# Strategy 1: Remove rows with missing critical information (if any)\n",
        "# data_cleaned = data_cleaned.dropna(subset=['id'])\n",
        "\n",
        "# Strategy 2: Impute missing values\n",
        "# For age: use median\n",
        "data_cleaned['age'].fillna(data_cleaned['age'].median(), inplace=True)\n",
        "\n",
        "# For income: use mean\n",
        "data_cleaned['income'].fillna(data_cleaned['income'].mean(), inplace=True)\n",
        "\n",
        "# For city: use mode (most frequent)\n",
        "city_mode = data_cleaned['city'].mode()[0]\n",
        "data_cleaned['city'].fillna(city_mode, inplace=True)\n",
        "\n",
        "# Verify missing values after imputation\n",
        "print(\"Missing values after imputation:\")\n",
        "print(data_cleaned.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Data Transformation and Feature Engineering\n",
        "\n",
        "## Create Derived Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create age groups\n",
        "def categorize_age(age):\n",
        "    if age < 25:\n",
        "        return 'Young'\n",
        "    elif age < 40:\n",
        "        return 'Adult'\n",
        "    elif age < 60:\n",
        "        return 'Middle-aged'\n",
        "    else:\n",
        "        return 'Senior'\n",
        "\n",
        "data_cleaned['age_group'] = data_cleaned['age'].apply(categorize_age)\n",
        "\n",
        "# Create income categories\n",
        "def categorize_income(income):\n",
        "    if income < 30000:\n",
        "        return 'Low'\n",
        "    elif income < 60000:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "data_cleaned['income_category'] = data_cleaned['income'].apply(categorize_income)\n",
        "\n",
        "print(\"Derived variables created successfully!\")\n",
        "print(\"Sample of new categorical variables:\")\n",
        "print(data_cleaned[['age', 'age_group', 'income', 'income_category']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4: Data Aggregation and Grouping Operations\n",
        "\n",
        "## Groupby Operations with Multiple Aggregations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate by age group\n",
        "age_group_summary = data_cleaned.groupby('age_group').agg({\n",
        "    'id': 'count',\n",
        "    'income': ['mean', 'median'],\n",
        "    'amount': ['sum', 'mean']\n",
        "}).round(2)\n",
        "\n",
        "# Flatten column names\n",
        "age_group_summary.columns = ['count', 'avg_income', 'median_income', 'total_amount', 'avg_amount']\n",
        "\n",
        "print(\"Summary by Age Group:\")\n",
        "print(age_group_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "This data wrangling exercise demonstrates essential skills for preparing data for analysis:\n",
        "\n",
        "1. **Data Loading**: Successfully imported and explored the dataset\n",
        "2. **Data Cleaning**: Handled missing values, cleaned text, and removed duplicates\n",
        "3. **Data Transformation**: Created derived variables, applied mathematical transformations, and encoded categorical variables\n",
        "4. **Data Aggregation**: Performed comprehensive grouping and aggregation operations\n",
        "\n",
        "The final dataset is now ready for further analysis, modeling, or visualization tasks.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
