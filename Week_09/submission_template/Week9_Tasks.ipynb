{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 9 Tasks — Data Mining with Python\n",
        "\n",
        "This notebook demonstrates fundamental data mining techniques including association rule mining, clustering, classification, and anomaly detection.\n",
        "\n",
        "**Author:** Your Name  \n",
        "**Date:** [Current Date]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data manipulation and numerical operations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data mining algorithms\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_curve, auc\n",
        ")\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Association rule mining\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_theme(style='whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Task 1 — Association Rule Mining\n",
        "\n",
        "In this task, we'll discover frequent itemsets and generate association rules from transactional data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Transactional Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load your transactional dataset\n",
        "# Example: Market basket data should be in a format where each row represents a transaction\n",
        "# and contains items purchased together\n",
        "\n",
        "# For demonstration, create sample transactional data\n",
        "# Replace this with your actual dataset loading\n",
        "transactions = [\n",
        "    ['Milk', 'Bread', 'Butter'],\n",
        "    ['Milk', 'Bread'],\n",
        "    ['Bread', 'Butter', 'Eggs'],\n",
        "    ['Milk', 'Eggs'],\n",
        "    ['Bread', 'Butter'],\n",
        "    # Add more transactions...\n",
        "]\n",
        "\n",
        "print(f\"Number of transactions: {len(transactions)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess Data for Apriori Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform transactions into a binary matrix\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df_transactions = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "print(f\"Transaction matrix shape: {df_transactions.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_transactions.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Find Frequent Itemsets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set minimum support threshold (e.g., 0.1 means item appears in at least 10% of transactions)\n",
        "min_support = 0.1\n",
        "\n",
        "# Find frequent itemsets using Apriori algorithm\n",
        "frequent_itemsets = apriori(df_transactions, min_support=min_support, use_colnames=True)\n",
        "\n",
        "print(f\"Number of frequent itemsets: {len(frequent_itemsets)}\")\n",
        "print(f\"\\nFrequent itemsets:\")\n",
        "frequent_itemsets.sort_values('support', ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Association Rules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate association rules\n",
        "min_confidence = 0.5  # Minimum confidence threshold\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "# Sort by lift (higher lift = stronger association)\n",
        "rules = rules.sort_values('lift', ascending=False)\n",
        "\n",
        "print(f\"Number of association rules: {len(rules)}\")\n",
        "print(f\"\\nTop 10 rules by lift:\")\n",
        "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top rules by lift\n",
        "top_rules = rules.head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(top_rules['support'], top_rules['confidence'], \n",
        "            s=top_rules['lift']*100, alpha=0.6, c=top_rules['lift'], cmap='viridis')\n",
        "plt.colorbar(label='Lift')\n",
        "plt.xlabel('Support')\n",
        "plt.ylabel('Confidence')\n",
        "plt.title('Association Rules: Support vs Confidence (Size = Lift)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "**Key Findings:**\n",
        "- [Explain the most interesting rules]\n",
        "- [Discuss business implications]\n",
        "- [Recommend actions based on rules]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Task 2 — Clustering Analysis\n",
        "\n",
        "In this task, we'll apply clustering algorithms to group similar data points together.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Dataset for Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load your dataset for clustering\n",
        "# Example: Customer segmentation, product features, etc.\n",
        "\n",
        "# For demonstration, create sample data\n",
        "# Replace this with your actual dataset loading\n",
        "# df_cluster = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Select numeric features for clustering\n",
        "# X = df_cluster.select_dtypes(include=[np.number])\n",
        "\n",
        "# Remove any missing values\n",
        "# X = X.dropna()\n",
        "\n",
        "print(\"Dataset loaded and prepared for clustering\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Determine Optimal Number of Clusters (Elbow Method)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize the features\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Calculate within-cluster sum of squares (WCSS) for different k values\n",
        "# k_range = range(2, 11)\n",
        "# wcss = []\n",
        "\n",
        "# for k in k_range:\n",
        "#     kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "#     kmeans.fit(X_scaled)\n",
        "#     wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Plot elbow curve\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(k_range, wcss, marker='o', linestyle='--')\n",
        "# plt.xlabel('Number of Clusters (k)')\n",
        "# plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "# plt.title('Elbow Method for Optimal k')\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Elbow method completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply K-Means Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose optimal k based on elbow method\n",
        "# optimal_k = 3  # Replace with your optimal k\n",
        "\n",
        "# Apply K-means\n",
        "# kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "# clusters_kmeans = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to dataframe\n",
        "# df_cluster['cluster_kmeans'] = clusters_kmeans\n",
        "\n",
        "# Print cluster centers\n",
        "# print(\"Cluster Centers:\")\n",
        "# print(kmeans.cluster_centers_)\n",
        "\n",
        "# Print cluster sizes\n",
        "# print(\"\\nCluster Sizes:\")\n",
        "# print(df_cluster['cluster_kmeans'].value_counts().sort_index())\n",
        "\n",
        "print(\"K-means clustering completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize K-Means Clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use PCA for 2D visualization if dataset has more than 2 features\n",
        "# pca = PCA(n_components=2)\n",
        "# X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_kmeans, \n",
        "#                      cmap='viridis', alpha=0.6, s=50)\n",
        "# plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
        "#            c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
        "# plt.xlabel(f'First Principal Component (Explained Variance: {pca.explained_variance_ratio_[0]:.2%})')\n",
        "# plt.ylabel(f'Second Principal Component (Explained Variance: {pca.explained_variance_ratio_[1]:.2%})')\n",
        "# plt.title('K-Means Clustering Results')\n",
        "# plt.colorbar(scatter, label='Cluster')\n",
        "# plt.legend()\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Visualization completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply DBSCAN Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply DBSCAN\n",
        "# eps = 0.5  # Maximum distance between samples in the same neighborhood\n",
        "# min_samples = 5  # Minimum number of samples in a neighborhood\n",
        "\n",
        "# dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "# clusters_dbscan = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels\n",
        "# df_cluster['cluster_dbscan'] = clusters_dbscan\n",
        "\n",
        "# Print number of clusters (excluding noise points labeled as -1)\n",
        "# n_clusters = len(set(clusters_dbscan)) - (1 if -1 in clusters_dbscan else 0)\n",
        "# n_noise = list(clusters_dbscan).count(-1)\n",
        "\n",
        "# print(f\"Number of clusters: {n_clusters}\")\n",
        "# print(f\"Number of noise points: {n_noise}\")\n",
        "# print(f\"\\nCluster Sizes:\")\n",
        "# print(pd.Series(clusters_dbscan).value_counts().sort_index())\n",
        "\n",
        "print(\"DBSCAN clustering completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare K-Means and DBSCAN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison visualization\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# # K-Means\n",
        "# scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_kmeans, \n",
        "#                           cmap='viridis', alpha=0.6, s=50)\n",
        "# axes[0].set_title('K-Means Clustering')\n",
        "# axes[0].set_xlabel('First Principal Component')\n",
        "# axes[0].set_ylabel('Second Principal Component')\n",
        "# axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# # DBSCAN\n",
        "# scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=clusters_dbscan, \n",
        "#                           cmap='viridis', alpha=0.6, s=50)\n",
        "# axes[1].set_title('DBSCAN Clustering')\n",
        "# axes[1].set_xlabel('First Principal Component')\n",
        "# axes[1].set_ylabel('Second Principal Component')\n",
        "# axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Comparison visualization completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "**Key Findings:**\n",
        "- [Explain cluster characteristics]\n",
        "- [Compare K-means vs DBSCAN results]\n",
        "- [Discuss when to use each method]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Task 3 — Classification with Decision Trees\n",
        "\n",
        "In this task, we'll build and evaluate a decision tree classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Classification Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load your classification dataset\n",
        "# Example: Iris, Wine Quality, Customer Churn, etc.\n",
        "\n",
        "# For demonstration:\n",
        "# df_classify = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Separate features and target\n",
        "# X = df_classify.drop('target_column', axis=1)\n",
        "# y = df_classify['target_column']\n",
        "\n",
        "# Handle categorical variables if needed\n",
        "# le = LabelEncoder()\n",
        "# y = le.fit_transform(y)\n",
        "\n",
        "print(\"Dataset loaded for classification\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Data into Training and Testing Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
        "# )\n",
        "\n",
        "# print(f\"Training set size: {X_train.shape[0]}\")\n",
        "# print(f\"Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "print(\"Data split completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Decision Tree Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train decision tree\n",
        "# dt = DecisionTreeClassifier(max_depth=5, random_state=42, min_samples_split=10)\n",
        "# dt.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "# y_pred = dt.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f\"Decision Tree Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"Decision tree trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the decision tree\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# plot_tree(dt, filled=True, feature_names=X.columns, \n",
        "#           class_names=[str(c) for c in np.unique(y)], fontsize=10)\n",
        "# plt.title('Decision Tree Structure')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Tree visualization completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "# precision = precision_score(y_test, y_pred, average='weighted')\n",
        "# recall = recall_score(y_test, y_pred, average='weighted')\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# print(f\"Precision: {precision:.4f}\")\n",
        "# print(f\"Recall: {recall:.4f}\")\n",
        "# print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Model evaluation completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "#             xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.ylabel('Actual')\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Confusion matrix created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "# feature_importance = pd.DataFrame({\n",
        "#     'feature': X.columns,\n",
        "#     'importance': dt.feature_importances_\n",
        "# }).sort_values('importance', ascending=False)\n",
        "\n",
        "# print(\"Feature Importances:\")\n",
        "# print(feature_importance)\n",
        "\n",
        "# Visualize feature importance\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "# plt.xlabel('Importance')\n",
        "# plt.title('Feature Importance in Decision Tree')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Feature importance analysis completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment with Different Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different max_depth values\n",
        "# depths = [3, 5, 7, 10, 15]\n",
        "# accuracies = []\n",
        "\n",
        "# for depth in depths:\n",
        "#     dt_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "#     dt_temp.fit(X_train, y_train)\n",
        "#     y_pred_temp = dt_temp.predict(X_test)\n",
        "#     accuracies.append(accuracy_score(y_test, y_pred_temp))\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(depths, accuracies, marker='o')\n",
        "# plt.xlabel('Max Depth')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Decision Tree Accuracy vs Max Depth')\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Parameter experimentation completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "**Key Findings:**\n",
        "- [Explain model performance]\n",
        "- [Discuss most important features]\n",
        "- [Analyze confusion matrix]\n",
        "- [Recommend parameter settings]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Task 4 — Anomaly Detection\n",
        "\n",
        "In this task, we'll identify anomalous data points using different detection methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Dataset for Anomaly Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Load your dataset for anomaly detection\n",
        "# Example: Fraud detection, network intrusion, manufacturing defects, etc.\n",
        "\n",
        "# For demonstration:\n",
        "# df_anomaly = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Select features for anomaly detection\n",
        "# X_anomaly = df_anomaly.select_dtypes(include=[np.number])\n",
        "\n",
        "# Standardize features\n",
        "# scaler_anomaly = StandardScaler()\n",
        "# X_anomaly_scaled = scaler_anomaly.fit_transform(X_anomaly)\n",
        "\n",
        "print(\"Dataset loaded for anomaly detection\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply Isolation Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply Isolation Forest\n",
        "# contamination = 0.1  # Expected proportion of anomalies (adjust based on your data)\n",
        "\n",
        "# iso_forest = IsolationForest(contamination=contamination, random_state=42)\n",
        "# anomalies_iso = iso_forest.fit_predict(X_anomaly_scaled)\n",
        "\n",
        "# Convert to binary (1 = normal, -1 = anomaly)\n",
        "# anomalies_iso_binary = (anomalies_iso == -1).astype(int)\n",
        "\n",
        "# print(f\"Number of anomalies detected: {sum(anomalies_iso_binary)}\")\n",
        "# print(f\"Percentage of anomalies: {sum(anomalies_iso_binary) / len(anomalies_iso_binary) * 100:.2f}%\")\n",
        "\n",
        "print(\"Isolation Forest completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply Local Outlier Factor (LOF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply LOF\n",
        "# n_neighbors = 20  # Number of neighbors to consider\n",
        "\n",
        "# lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
        "# anomalies_lof = lof.fit_predict(X_anomaly_scaled)\n",
        "\n",
        "# Convert to binary\n",
        "# anomalies_lof_binary = (anomalies_lof == -1).astype(int)\n",
        "\n",
        "# print(f\"Number of anomalies detected: {sum(anomalies_lof_binary)}\")\n",
        "# print(f\"Percentage of anomalies: {sum(anomalies_lof_binary) / len(anomalies_lof_binary) * 100:.2f}%\")\n",
        "\n",
        "print(\"LOF completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Anomalies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use PCA for 2D visualization\n",
        "# pca_anomaly = PCA(n_components=2)\n",
        "# X_anomaly_pca = pca_anomaly.fit_transform(X_anomaly_scaled)\n",
        "\n",
        "# Create comparison visualization\n",
        "# fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# # Isolation Forest\n",
        "# scatter1 = axes[0].scatter(X_anomaly_pca[:, 0], X_anomaly_pca[:, 1], \n",
        "#                            c=anomalies_iso_binary, cmap='RdYlGn', alpha=0.6, s=50)\n",
        "# axes[0].set_title('Isolation Forest Anomaly Detection')\n",
        "# axes[0].set_xlabel('First Principal Component')\n",
        "# axes[0].set_ylabel('Second Principal Component')\n",
        "# axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# # LOF\n",
        "# scatter2 = axes[1].scatter(X_anomaly_pca[:, 0], X_anomaly_pca[:, 1], \n",
        "#                            c=anomalies_lof_binary, cmap='RdYlGn', alpha=0.6, s=50)\n",
        "# axes[1].set_title('Local Outlier Factor Anomaly Detection')\n",
        "# axes[1].set_xlabel('First Principal Component')\n",
        "# axes[1].set_ylabel('Second Principal Component')\n",
        "# axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Anomaly visualization completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare agreement between methods\n",
        "# agreement = (anomalies_iso_binary == anomalies_lof_binary).sum()\n",
        "# total = len(anomalies_iso_binary)\n",
        "\n",
        "# print(f\"Agreement between methods: {agreement}/{total} ({agreement/total*100:.2f}%)\")\n",
        "\n",
        "# Create comparison dataframe\n",
        "# comparison_df = pd.DataFrame({\n",
        "#     'Isolation Forest': anomalies_iso_binary,\n",
        "#     'LOF': anomalies_lof_binary\n",
        "# })\n",
        "\n",
        "# print(\"\\nComparison Summary:\")\n",
        "# print(comparison_df.sum())\n",
        "\n",
        "print(\"Method comparison completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "**Key Findings:**\n",
        "- [Explain detected anomalies]\n",
        "- [Compare Isolation Forest vs LOF]\n",
        "- [Discuss characteristics of anomalous points]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Task 5 — Model Evaluation and Comparison\n",
        "\n",
        "In this task, we'll compare multiple classification algorithms and select the best performing model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Multiple Classification Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multiple models\n",
        "# models = {\n",
        "#     'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
        "#     'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "#     'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
        "# }\n",
        "\n",
        "# results = {}\n",
        "\n",
        "# for name, model in models.items():\n",
        "#     # Train model\n",
        "#     model.fit(X_train, y_train)\n",
        "#     \n",
        "#     # Make predictions\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     \n",
        "#     # Calculate metrics\n",
        "#     results[name] = {\n",
        "#         'Accuracy': accuracy_score(y_test, y_pred),\n",
        "#         'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "#         'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "#         'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
        "#     }\n",
        "\n",
        "# Convert to DataFrame\n",
        "# results_df = pd.DataFrame(results).T\n",
        "# print(\"Model Comparison:\")\n",
        "# print(results_df.round(4))\n",
        "\n",
        "print(\"Multiple models trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform cross-validation\n",
        "# cv_scores = {}\n",
        "\n",
        "# for name, model in models.items():\n",
        "#     scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "#     cv_scores[name] = {\n",
        "#         'Mean': scores.mean(),\n",
        "#         'Std': scores.std()\n",
        "#     }\n",
        "\n",
        "# cv_df = pd.DataFrame(cv_scores).T\n",
        "# print(\"Cross-Validation Results:\")\n",
        "# print(cv_df.round(4))\n",
        "\n",
        "print(\"Cross-validation completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison bar chart\n",
        "# fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "# for idx, metric in enumerate(metrics):\n",
        "#     ax = axes[idx // 2, idx % 2]\n",
        "#     results_df[metric].plot(kind='bar', ax=ax, color='steelblue')\n",
        "#     ax.set_title(f'{metric} Comparison')\n",
        "#     ax.set_ylabel(metric)\n",
        "#     ax.set_ylim([0, 1])\n",
        "#     ax.grid(True, alpha=0.3, axis='y')\n",
        "#     plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "\n",
        "print(\"Comparison visualization completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC Curve (for Binary Classification)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For binary classification only\n",
        "# if len(np.unique(y)) == 2:\n",
        "#     plt.figure(figsize=(10, 8))\n",
        "#     \n",
        "#     for name, model in models.items():\n",
        "#         model.fit(X_train, y_train)\n",
        "#         y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "#         fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "#         roc_auc = auc(fpr, tpr)\n",
        "#         plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
        "#     \n",
        "#     plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "#     plt.xlabel('False Positive Rate')\n",
        "#     plt.ylabel('True Positive Rate')\n",
        "#     plt.title('ROC Curve Comparison')\n",
        "#     plt.legend()\n",
        "#     plt.grid(True, alpha=0.3)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "print(\"ROC curve analysis completed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best model based on F1-score (or your preferred metric)\n",
        "# best_model_name = results_df['F1-Score'].idxmax()\n",
        "# best_score = results_df.loc[best_model_name, 'F1-Score']\n",
        "\n",
        "# print(f\"Best Model: {best_model_name}\")\n",
        "# print(f\"Best F1-Score: {best_score:.4f}\")\n",
        "# print(f\"\\nAll Metrics for Best Model:\")\n",
        "# print(results_df.loc[best_model_name])\n",
        "\n",
        "print(\"Best model selected\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "**Key Findings:**\n",
        "- [Compare model performances]\n",
        "- [Explain why the selected model is best]\n",
        "- [Discuss trade-offs between models]\n",
        "- [Recommend model for deployment]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary and Conclusions\n",
        "\n",
        "This data mining exercise demonstrates essential techniques for pattern discovery and knowledge extraction:\n",
        "\n",
        "1. **Association Rule Mining**: Discovered frequent patterns and relationships in transactional data\n",
        "2. **Clustering**: Grouped similar data points using K-means and DBSCAN algorithms\n",
        "3. **Classification**: Built and evaluated decision tree models for prediction\n",
        "4. **Anomaly Detection**: Identified outliers using Isolation Forest and LOF methods\n",
        "5. **Model Comparison**: Evaluated and compared multiple classification algorithms\n",
        "\n",
        "**Key Insights:**\n",
        "- [Summarize main findings]\n",
        "- [Discuss practical applications]\n",
        "- [Recommend next steps]\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
