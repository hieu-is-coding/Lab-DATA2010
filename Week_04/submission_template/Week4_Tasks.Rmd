---
title: "Week 4 Tasks — Advanced Data Analysis and Modeling (R)"
author: "Your Name"
output:
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(lubridate)
library(broom)
theme_set(theme_minimal())
```

# Instructions

- Use this template to complete Week 4 tasks. Replace placeholders with your work.
- Ensure the document can knit top-to-bottom without errors.
- Build upon your Week 3 analysis or use a new dataset.
- Add short captions/annotations below each result.

# Task 1 — Class Imbalance (if applicable)

```{r imbalance}
# If classification target exists
# data %>% count(target) %>% mutate(p = n/sum(n))

# If imbalance exists, apply a strategy:
# Example: SMOTE, class weights, or stratified sampling
# library(ROSE)
# balanced_data <- ROSE(target ~ ., data = data)$data
```

Brief description of your approach to handle class imbalance (if applicable).

# Task 2 — Feature Engineering

```{r feature-engineering}
# Examples: date parts, one-hot via model.matrix, binning, scaling
# data <- data %>% 
#   mutate(
#     month = month(date_col),
#     desc_len = nchar(text_col),
#     numeric_binned = cut(numeric_col, breaks = 5)
#   )

# Create interaction terms or polynomial features if needed
# data <- data %>% mutate(interaction = var1 * var2)
```

Describe the 2+ features you created and why they might be useful for modeling.

# Task 3 — Baseline Modeling

```{r baseline-modeling}
# Example classification baseline (adapt to your data)
# target <- "target"
# features <- c("feature1", "feature2", "feature3")
# model_data <- data %>% select(all_of(c(features, target))) %>% drop_na()

# Simple train/test split
# set.seed(42)
# idx <- sample(nrow(model_data), size = floor(0.8 * nrow(model_data)))
# train <- model_data[idx, ]
# test  <- model_data[-idx, ]

# Fit baseline model (logistic regression for classification, lm for regression)
# fit <- glm(as.formula(paste(target, "~ .")), data = train, family = binomial())
# summary(fit)
```

Show your model training code and briefly describe your baseline approach.

# Task 4 — Evaluation

```{r evaluation}
# Generate predictions
# preds <- predict(fit, newdata = test, type = "response")
# pred_class <- if_else(preds > 0.5, 1, 0)

# Calculate metrics
# accuracy <- mean(pred_class == test[[target]])
# 
# # For classification: precision, recall, F1
# library(caret)
# confusionMatrix(factor(pred_class), factor(test[[target]]))
#
# # For regression: RMSE, MAE, R²
# # rmse <- sqrt(mean((preds - test[[target]])^2))
# # mae <- mean(abs(preds - test[[target]]))

# Display key metrics
# tibble(
#   accuracy = accuracy,
#   # Add other relevant metrics
# )
```

Provide a 2–4 sentence interpretation of your metrics and what they imply about model performance.

# Task 5 — Findings and Next Steps

## Key Insights

Summarize 3–5 insights from your analysis and modeling:

1. 
2. 
3. 
4. 
5. 

## Next Steps

Propose 2 concrete next steps to improve the analysis or model:

1. 
2. 

